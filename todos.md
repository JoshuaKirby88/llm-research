- [ ] Add messagePromptId to messagePrompt
- [ ] Show clerk name
- [ ] Check if deleting non-existant vector errors
- [ ] Make sure strings in new research form has min value
- [ ] I'm inserting eval completion as the completion
- [ ] What if a research doesn't have any blocking variables
- [ ] Fork a research, will redirect to new research page with all fields pre-filled, so user can edit as they like
- [ ] Show evaluation beneath messages, separated by line, with the prompt in dialog as well
- [ ] Instruct LLM to only respond with the prompt when generating messages
- [ ] Visually mark replaced variables when showing messages
- [ ] Show total iterations in run test form

# New research form

- [ ] Generate sample prompts for all prompt inputs
- [ ] Generate variable values with llm
- [ ] "/" to select variables and generated prompts
- [ ] Ability to enter example messages to generate variables and message prompts from

# Research examples

- Does language consistency affect accurancy?
- Do LLMs bias toward identified over anonymous individuals?
- Should conversation history be in individual messages or user prompt?
