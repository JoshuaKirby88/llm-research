- [ ] Replace completion variable
- [ ] Run test errors with multiple models
- [ ] What if a research doesn't have any blocking variables
- [ ] Instruct LLM to only respond with the prompt when generating messages
- [ ] Visually mark replaced variables when showing messages
- [ ] Show total iterations in run test form
- [ ] Implement transaction with a callback that fires on error
- [ ] Check if deleting non-existant vector errors

# New research form

- [ ] Make sure strings in new research form has min value
- [ ] Generate sample prompts for all prompt inputs
- [ ] Generate variable values with llm
- [ ] "/" to select variables and generated prompts
- [ ] Ability to enter example messages to generate variables and message prompts from
- [ ] Fork a research, will redirect to new research page with all fields pre-filled, so user can edit as they like

# Research examples

- Does language consistency affect accurancy?
- Do LLMs bias toward identified over anonymous individuals?
- Should conversation history be in individual messages or user prompt?
